\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{moreverb}
\usepackage{graphicx}
\usepackage{hyperref}


\title{Project Report for WeezelTV\\ EDA095 Network Programming}
\date{\today}
\author{Fredrik Paulsson \\ dat11fp1@student.lu.se \and Jonas Jacobsson \\ dat11jja@student.lu.se \and Artur Matulaniec \\ dat11ama@student.lu.se \and Magnus TÃ¶rnquist \\ ada08mto@student.lu.se}
%\setcounter{secnumdepth}{5}
%\setcounter{tocdepth}{5}
\begin{document}
\maketitle
%\tableofcontents

\newpage
\section{Introduction}
The project in this course did not contain a specific task that was to be done. Rather, the only demand was that the content of the course was to be of central focus in the project.

Since the course was about network programming we decided that our project were to be based on video streaming. Basically we wanted to stream video from a server to a client. At first we wanted to implement the server part using well-known protocols such as RTSP/RTCP/RTP and then connect our server to an already existing client such as VLC.

However, later on we decided to skip these existing protocols and implement our own client/server solution using a simple protocol that we defined ourselves.

This report will serve as documentation of our project work.

\section{Implementing a server using RTP/RTSP}
As mentioned in the introduction we started off the project by trying to implement a RTP/RTSP server hoping to be able to stream to VLC. 
Some sample code was provided to us containing a server and client using a very simplified version of RTP/RTSP. The server used RTSP to setup the connection with the client then created byte arrays of jpeg images from a file in the mjpeg format.
This code was our main foundation for trying to build a RTP server capable of streaming to VLC instead of the provided client. Unfortunately it turned out that there were many obstacles in the way.
First we encountered several small problems, for example the sample code did not use EOL properly and thus VLC didn't know the server had finished sending an RTSP packet. Another example is that the server wanted responses to look in particular way and couldn't understand what VLC was sending.
A third example is that VLC wanted to decide the client port in the SETUP method and therefore we had to extract that and use the port in the connection.
These problems were rather easily fixed. Then came a slightly bigger problem: It turned out that VLC required the RTSP method "DESCRIBE" to be used even though the RFC for RTSP states that it's only a recommended method\footnote{https://www.ietf.org/rfc/rfc2326.txt}.
Implementing a DESCRIBE method that was fully functional in all cases would be tricky (see section 10.2 in the RFC), so we decided to focus on giving VLC the correct information for that particular mjpeg file. 
When this was done VLC was finally satisfied and a connection was established, but for some reason no packets were being received on the clients end. It was just waiting until it timed out.
We fired up Wireshark to analyze what had gone wrong and saw plenty of packets that Wireshark did not recognize. After further inspection we realized that those were our RTP packets but with an incorrect header.
The RTP sample code had completely skipped the beginning of the header that includes important things like padding and payload type. So we figured out what we wanted the header to be and manually set the beginning of the header to [10000000]\footnote{For details: https://www.ietf.org/rfc/rfc3550.txt} and payload type 26 (mjpeg).
Now VLC was finally receiving the packets, recognizing them as RTP packets with an mjpeg payload and handed of the decoding procedure to the open source library "LIVE555".
LIVE555 failed to decode the packets. This was when we started to run of patience. It turned out that when sending mjpeg via RTP it requires a special header on all jpeg images. 
When we were taking a look at the RFC for RTP Payload Format for JPEG-compressed Video\footnote{Found here: https://tools.ietf.org/html/rfc2435} we realized that we had bitten of more than we could chew and decided to scrap this whole approach.

This code is still available but we decided not to include it here since it's irrelevant to the rest of the project. 

\section{Features/Requirements}
When we began our project we did set quite straight forward requirements regarding what we wanted our software to handle. To begin with we did some research and thought of using an already implemented protocol in order to be able to use standard software regarding the video showing, as mentioned before. Hence, the main objective of our software was that we would implement a server, a client and be able to connect to that server, preferably with more than one client at a time, and stream video to it/them in real time. Along the way, however, more features came to our minds and we did found ourselves having requirements as show in the list below.

\begin{itemize}
\item A server with some videos and being able to handle more than one client at a time.
\item A client with our own GUI.
\item The possibility of choosing a video to stream.
\item Being able to play and pause.
\item Building our own protocol in order to minimize the complexity of the software. 
\item Optional, to have the video streamed with audio.
\end{itemize}

Those were the features which we finally decided to add to our software and project. 


\section{Structure/Model}
Our solution consists of two parts, a server and a client. These are two independent programs that communicates using a protocol that we personally defined. The underlying transport protocol is, however, regular TCP. Since we have two different independent programs we will divide this section in order to describe each and one of them more specifically. There is also a common packet shared by the two programs in order for them to be able to communicate. 

\subsection{Common}
Under this packet we have both the protocol and the common configuration file, which is use to maintain all the parameters into the program. The protocol consists of a couple of bytes which are sent over the network to one of the entities in order to perform commands from one entity to the other. Under this common packet we also have the two buffer element types, 
\begin{itemize}
\item \texttt{AudioBufferElement}
\item \texttt{ImageBufferElement}
\end{itemize}

which describes the elements of both the video and audio in order to send them over the network. As well as their structure is considered crucial in order to maintain the synchronization between the two parts when streaming video over the network. 

\subsubsection{Protocol}
Since this project is about network programming some information about the protocol could be explained. Our protocol uses regular bytes as the data to be sent, since then there is no need for converting any other data type. We have divided it into two parts, 

\begin{enumerate} 
\item Server to client commands
\item Client to server commands
\end{enumerate}

to be able to divide the communication, and also for the ease of adding new commands throughout. 

In most cases the protocol is just one byte sent from one end to the other, for example, when we push the button to start the stream and stop it. For frames, audio samples and available movies the protocol is one byte indicating what type of message it is, then some ints, longs and floats describing necessary data, such as timestamps. After this we send how many bytes the actual frame or sample is and finally the frame or sample itself. In the case of the movie list, the number of strings are sent instead.

We use \texttt{DataInputStream} and \texttt{DataOutputStream} defined in the Java standard library to send and receive our data.

\subsection{Server}
The server is divided into different classes for the maintainability of the server. However, the most important part is the \texttt{ServerSender} class. This class is the class which sends the data over the network, for both image and audio samples. This is the monitor shared by the two threads, \texttt{ImageSender} and \texttt{AudioSender}, which are responsible to provide the monitor with samples to be sent to a connected client. 

The server also has a buffer, the class \texttt{ServerBuffer}, which holds the samples. The common structure for the buffers is that they both use LinkedList as the data container. The class \texttt{ServerListener} is a class which encodes the file found on the server into the two common shared data structures mentioned above. This class is responsible to provide the buffer with the samples in order for the two senders, \texttt{ImageSender} and \texttt{AudioSender} to be able to send the information to the \texttt{ServerSender} and next out on the network.

To be able to read any commands sent from the client, the thread \texttt{ServerReceiver} is running and reading the bytes sent from the client. Based on which command is being sent, it performs different action on the buffer and in that way the server is controlled by the client. 

The main method of the server is to be found in the class \texttt{Server}.   
\subsection{Client}
The client is also divided into a couple of classes for the maintainability of the software. The most important part of the client is the thread \texttt{ClientReceiver}. The thread is responsible to receive the sent information from the server and sends it into the clients buffer, class \texttt{ClientBuffer}. The buffer then works as a monitor for the rest of the client, since all the other threads also uses it to receive information and show it onto the GUI. As in the server, the buffer uses LinkedList as the data container and there are two, one for each of the common shared data elements. 

Another important part of the client is the two threads, \texttt{ClientImageViewer} and \texttt{ClientSoundPlayer}. Those threads are responsible for the synchronization between the video and the audio. The \texttt{ClientImageViewer} is also responsible to add image samples into the GUI in order to show the video stream. 

The GUI, class \texttt{ClientGUI} is responsible for everything that happens with the end user. The GUI takes use of the monitor, \texttt{ClientSender}, to be able to send commands to the server from the client. The \texttt{ClientSender} is responsible to maintain the connection with the \texttt{ServerReceiver} in order for the end user to send commands from the client to the server. 

The main method for the client is to be found in the class \texttt{Client}. 
\subsection{Library}
%Här beskriver vi xuggle lite kortfattat, lägg gärna till referenser. Problemen med xuggle tykcer jag vi tar i diskussionen
For the encoding library we found a library, which suited our needs, called \emph{Xuggler\footnote{For more specific information: http://www.xuggle.com/xuggler}}. Xuggler is a library which uses the free software project, FFmpeg, to encode and decode all kinds of video files. We chose Xuggler since it had a quite easy API and the methods used suited our solution with the live streaming of a video over a network. Xuggler also spoke to us since we were able to get some example code and get to know the way the library is built up. 

\clearpage
\section{User Guide}
%manual
\subsection{Configuration}

\begin{itemize}
  \item To configure the program you first need to locate the config file and open it with a text editing program.
  \item When it is open you can change the following settings how you please to have them for an optimal viewing experience:

\begin{itemize}
  \item COM\_PORT (The port that should be used by the program)
  \item CLIENT\_BUFFER\_SIZE (Size of the image buffer for the client)
  \item CLIENT\_HOST (The address to the host of the client)
  \item SERVER\_COMPRESSION\_QUALITY (How much the server should compress the images before sending them)
  \item SERVER\_MEDIA\_DIRECTORY (The path to the media files)
  \item SERVER\_BUFFER\_SIZE (Size of the image buffer for the server)
  \item SERVER\_WAIT\_TIME (Wait time for the server)
  \item SERVER\_BLOCK\_SIZE ()
\end{itemize}
\end{itemize}

\subsection{Starting the program}
\begin{itemize}
  \item To start the program, first need to execute the \emph{server.jar}.
  \item Then you need to execute the \emph{client.jar}.
  \item When \emph{client.jar} is running, there will appear a application window.
  \item Now the program is started.
\end{itemize}

\subsection{Starting a movie}
\begin{itemize}
  \item To start a movie, first the program first need to be started.
  \item In the application window, click on the tab \emph{Select Panel}.
  \item In this panel a list of the movies available will be shown. Choose a movie by clicking on it.
  \item Then click \emph{Select} to verify your choice.
  \item Click on the tab \emph{Movie Panel} to get back to the movie screen.
  \item Here you first need to start the movie stream to the client by clicking on \emph{Start stream}.
  \item Now the movie is streaming to your computer and will start when the buffering is complete.
\end{itemize}

\subsection{Pausing and starting the movie stream}
\begin{itemize}
  \item While a movie is playing you can pause the movie stream at any point just by clicking on the button \emph{Pause stream}.
  \item You can notice that the number of frames and audio samples will decrease, because the client do not receive new ones anymore.
  \item To start the movie stream again you need to click on the button \emph{Start stream}, and the frames and audio samples will start to increase again.
\end{itemize}

\subsection{Set movie to pause/play}
\begin{itemize}
  \item While a movie is playing you can click the button \emph{Pause}, or click the movie screen, to pause the movie.
  \item Now the movie is paused. To start playing it again you just need to click the button \emph{Play}, or click the movie screen.
\end{itemize}

\subsection{Switch between default and fullscreen mode}
\begin{itemize}
  \item While a movie is playing, or is paused, you can set the application window to a fullscreen mode by double clicking on the movie screen.
  \item Now the application window will adjust itself to your computer screen.
  \item To get back to the default mode you just need to double click on the movie screen again.
\end{itemize}

\subsection{Closing}
\begin{itemize}
  \item In any time you would like to exit the program, you just need to go to the tab \emph{Main Panel}.
  \item In the \emph{Main Panel}, click on the button \emph{Exit}.
  \item The program will close.
\end{itemize}

%For the user manual, please refer to our project website, \href{http://users.student.lth.se/dat11ama/hemsida/styled-2/styled-5/}{press here}\footnote{If not reading on a computer: http://users.student.lth.se/dat11ama/hemsida/styled-2/styled-5/}.

\section{Evaluation/Discussion}
%kolla rapportgrejsen som jag lÃ¤nkat till: http://fileadmin.cs.lth.se/cs/Education/EDA095/2010/projektrapport.pdf
With the finished software we actually accomplished more then we thought, since the main part to be able to actually only stream video. We did manage to actually get both the video and the audio working, and at the same time being synchronized. The GUI was meant to be quite straight forward, but since we did get a tip of a software from our mentor, we actually made it much more nicer then what we thought of how it would be. Hence, in other words, our requirements were reached. There is a maybe that because of this software from our mentor, the GUI class contains every part of the GUI. For the complexity of a class this could become a handfull if the class grows, hence, a different design approach with different separated classes would be a good idea for us. 

Having this said, what could be changed with our project. Firstly, since we now use our own protocol and GUI, there is no room for us to extract the server and letting it connect to a media player of ones choice, since they use the standard protocol RTP and RTSP. This is something we could have worked with, but the majority of this transformation is to big and complex for it to be worth to do. Most of our design would have to change and it would probably be easier to start with a new project. 

Another thing which could have be done in another way for the project was the fact that we chose a rather unknown for us library, Xuggler. Xuggler from day one had us cornered and we spent endless hours to just getting it work on our computers. When we finally did get it working, the struggle now was how to extract the samples from the decoder. It was a kind of black box scenario that we inserted a video file, got it to play locally but did not know how in the world it could be received out of the encoder. Another couple of hours spent on reading and searching for information before we did get everything we needed. Needles to say, Xuggler is actually pretty good when you get it to work, however, with the lack of documentation it could become a headache for the developer. Those hours we spent on researching and almost giving up the idea of the video streaming project could we have spent much more productive. 

It was a rather interesting challenge for us to syncronize the video and audio, both to syncronize the frames and samples in between themsleves but also together. Since we really did not believe that we would manage audio the first method of syncronizing the frames was to look at two adjacent frames and calculate the time that were gonna pass in between they are shown and then wait that time. Using this method the video became perfectly synced. However, when we applied the same method to the audio, the audio was cut off and on and it did not sync with the video. There were two problems with this, the audio is played in it's own time axis which means that we must discard those samples that are already to late to be played, this is not the case for the video as the the frame would be exchanged again very quickly. The other problem was of course that using our method to sync the video and audio there were never any syncing in between the audio and the video against each other. The solution was to set a timestamp when the video was started and then to sync everything from there. The time the stream is paused is counted and accumulated and every frame and sample is displaced by this time. This resulted in what we think is perfect syncronization.

We also have a really peculiar problem. The server and client are extremely memory inefficient, especially when the client is paused and is still receiving data from the server. This is because it will buffer up every frame and audio sample. Also the server crashes after a while if the movie is large enough. Using a memory analyzer we deduced the problem to be the \texttt{LinkedList} used as a queue for the video frames in the server's buffer. At our meausurement it took 1.5 GB of memory. We cannot for the life of us figure what is happening here. The queue does never contain any more than 100 frames (default settings) and we do lose references to the objects that we take out. One would think that the garbage collector in Java ought to clean up but apparently that is not the case. One idea is to replace the queue with an array and using it as a circular queue instead. However we are afraid that this would not mitigate the problem. It may be that Xuggler is actually keeping references to the frames which prevents the garbage collector from running but we do not know. The strange thing is that the garbage collector work as expected in the client yet there is virtually no difference between the two queues except for the library in the server. Needless to say, before adding anything more to the functionality in our program, on emust first sort out the memory problems. We did try to minimize both memory usage and network usage in the program by compressing the frames. Unfortunately this did not solve our mystery black hole of memory in the server.

However, in the larger scale, we are very pleased with what we have accomplished during this course. There is not much we would have changed, but if we had to do this again, we would know more and maybe could build something more complex with some other functionality. The course and project is very appealing to the education, since it contains both programming, documentation and the chance to explore our imagination. There is not much more to change, the mentor we had gave us input and we could use him as an idea wall were we would together as a group come up with ideas and make a decision. 
\section{Source Code}
%Vi beskriver bara hur källkoden är organiserad, för mycket att inkludera allt
The source code is divided into three packages, as shown in the list below. However, for download please refer to our project website, \href{http://users.student.lth.se/dat11ama/hemsida/downloads/}{press here}\footnote{If not reading on a computer: http://users.student.lth.se/dat11ama/hemsida/downloads/}. For the overall design description, please refer to Section 4 in this paper. 

\begin{itemize}
\item \texttt{WeezelTV.common}. This package contains the protocol and the common shared files with the overall system.
\item \texttt{WeezelTV.client}. This package contains the classes for the client, GUI etc.
\item \texttt{WeezelTV.server}. This package contains the classes for the server. 
\end{itemize}




%\begin{thebibliography}{1}
%\bibitem{wikipedia}
%http://en.wikipedia.org
%\end{thebibliography}
\end{document}
